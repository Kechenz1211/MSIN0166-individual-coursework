{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jyeifhIzTFL",
        "outputId": "c8808b06-1ab1-4215-a2af-92a0dfd16391"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging>=20.9 (from huggingface_hub)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence_transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "KYZGghcszj-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "HUGGINGFACE_API_TOKEN=getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJieJU1Gz4bX",
        "outputId": "d6a79d03-ad51-4c35-9923-38e8fc69ad93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=HUGGINGFACE_API_TOKEN"
      ],
      "metadata": {
        "id": "Mj3GZpX01AeO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "H-k2hOjq1TGi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model\n",
        "question=\"Where is the capital of China?\"\n",
        "template=\"\"\" Question: {question} Answer:let's think step by step.\"\"\"\n",
        "\n",
        "prompt=PromptTemplate(template=template,input_variables=['question'])"
      ],
      "metadata": {
        "id": "ovYIBiRK2Kx9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id='google/flan-t5-base'"
      ],
      "metadata": {
        "id": "NoAYt6YK29sc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFaceHub(\n",
        "    repo_id=repo_id\n",
        ")\n",
        "llm_chain=LLMChain(prompt=prompt,llm=llm,llm_kwargs={\"temperature\":0,\"max_length\":512})\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBfDgeHY3N3Q",
        "outputId": "798341f4-af3d-4886-8d13-c50e91ec2faf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "China is a country located in the north of China. The capital of China is Beijing. The answer: Beijing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG search"
      ],
      "metadata": {
        "id": "UIvi50H35ZCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "#from langchain.vectorstores import FAISS\n",
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "5rmZpXy_4xwN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "6VEoduffJKN0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "loader = CSVLoader(file_path=\"new_processed_file.csv\")\n",
        "pages= loader.load()\n",
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter= RecursiveCharacterTextSplitter(chunk_size=300,chunk_overlap=50,)\n",
        "docs=text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "8txJ3b845t2t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)\n",
        "type(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "liXpdy4aLpYv",
        "outputId": "9346c69d-2263-4ae2-af5a-a99c2ff775d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 9);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether the docs is empty\n",
        "if not docs:\n",
        "    print(\"the splitted file is empty\")\n",
        "else:\n",
        "    print(f\"generate {len(docs)} files\")\n",
        "\n",
        "print(f\"Loaded {len(pages)} pages.\")\n",
        "print(f\"Split into {len(docs)} documents.\")\n",
        "\n",
        "doc = docs[0]\n",
        "print(dir(doc))\n",
        "print(doc)\n",
        "print(docs)\n",
        "\n",
        "os.environ[\"HUGGINGFACE_API_TOKEN\"] = HUGGINGFACE_API_TOKEN\n",
        "\n",
        "dir(docs)"
      ],
      "metadata": {
        "id": "yiOzAY3CAvCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(docs[0]))\n",
        "print(dir(docs[0]))\n",
        "texts = [doc.page_content for doc in docs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxYYfOi2NR7b",
        "outputId": "a19ba838-aa02-4cf1-f0dc-e8c60d1d2f4d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "['Config', '__abstractmethods__', '__annotations__', '__class__', '__class_vars__', '__config__', '__custom_root_type__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__exclude_fields__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_validators__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__include_fields__', '__init__', '__init_subclass__', '__iter__', '__json_encoder__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__post_root_validators__', '__pre_root_validators__', '__pretty__', '__private_attributes__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__schema_cache__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__try_update_forward_refs__', '__validators__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_decompose_class', '_enforce_dict_if_root', '_get_value', '_init_private_attributes', '_iter', '_lc_kwargs', 'construct', 'copy', 'dict', 'from_orm', 'get_lc_namespace', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'metadata', 'page_content', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'type', 'update_forward_refs', 'validate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings=HuggingFaceInferenceAPIEmbeddings(\n",
        "    api_key=HUGGINGFACE_API_TOKEN, model_name='BAAI/bge-base-en-v1.5'\n",
        ")"
      ],
      "metadata": {
        "id": "De6EL1vQ72AZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test whether the embeddings work\n",
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "query_result"
      ],
      "metadata": {
        "id": "RqrB0aEwRLTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu # this package is required to use the FAISS\n",
        "\n",
        "## Create a FAISS database from documents and their embeddings.\n",
        "# This database will be used for similarity searches.\n",
        "db=FAISS.from_documents(docs,embeddings)\n",
        "\n",
        "# Define a query to search within the documents.\n",
        "query='Who is the author of Chani is the real protagonist of Dune: Part Two?'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86C8hkJ5K4iX",
        "outputId": "9a12358f-40d3-4bc6-f9ef-2094864a79e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the page content of the first document for inspection purposes.\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNFL3vm6Tp7J",
        "outputId": "7df4afbf-5fbd-4380-9dcc-a62a3a2b9b65"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author: \n",
            "title: Forian GAAP EPS of $0.04 beats by $0.07, revenue of $5.37M misses by $0.19M\n",
            "description: Forian GAAP EPS of $0.04 beats by $0.07, revenue of $5.37M misses by $0.19M\n",
            "source: Seeking Alpha\n",
            "category: business\n",
            "date: 2024-03-28T20:26:56+00:00\n",
            "release_time: 2024-03-28T20:26:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a similarity search in the FAISS database with the specified query\n",
        "# and retrieving the top 3 similar items.\n",
        "result_simi = db.similarity_search(query , k = 3)"
      ],
      "metadata": {
        "id": "t0vYWqY0Up3z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_simi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WswMZyYiY3Ic",
        "outputId": "074b307c-2a53-46c2-c906-eb87a9313f5b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='author: Austen Goslin\\ntitle: Chani is the real protagonist of Dune: Part Two\\ndescription: Photo: Chiabella James/Warner Bros. Pictures This is Zendaya’s movie, and the storytelling choices reflect it Continue reading&hellip;\\nsource: Polygon\\ncategory: entertainment\\ndate: 2024-03-28T20:16:16+00:00', metadata={'source': 'new_processed_file.csv', 'row': 18}),\n",
              " Document(page_content='author: Jeffrey Parkin\\ntitle: ‘Readvent of Calamity’ quest walkthrough in Dragon’s Dogma 2\\ndescription: Image: Capcom via Polygon Where to find Ulrika in Melve ‘from time to time’ Continue reading&hellip;\\nsource: Polygon\\ncategory: entertainment\\ndate: 2024-03-26T20:57:25+00:00', metadata={'source': 'new_processed_file.csv', 'row': 65}),\n",
              " Document(page_content='author: Akashdeep Banerjee\\ntitle: Unveiling 76ers’ ‘Worst Kept Secret’: LeBron James, Kawhi Leonard, and Paul George Saga', metadata={'source': 'new_processed_file.csv', 'row': 45})]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate the page contents of the top 3 similar items into a single string, separated by new lines.\n",
        "# This aggregated content serves as the source knowledge context for answering the query.\n",
        "source_knowledge = \"\\n\".join([x.page_content for x in result_simi])\n",
        "\n",
        "# Construct an augmented prompt that includes both the source knowledge context and the query.\n",
        "# This prompt is structured to facilitate the generation of an answer based on the provided context.\n",
        "augmented_prompt = \"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "contexts:\n",
        "{source_knowledge}\n",
        "\n",
        "query: {query}\"\"\"\n"
      ],
      "metadata": {
        "id": "dQ4yTAUTUt35"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=augmented_prompt, input_variables=[\"source_knowledge\" ,\"query\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm  , llm_kwargs = {\"temperature\":0, \"max_length\":1024})\n",
        "\n",
        "print(llm_chain.run( {\"source_knowledge\":source_knowledge ,\"query\" : query }))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARaxEeQeU4ZY",
        "outputId": "d71679d8-91bc-405d-9c8c-14f1df4dfb82"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Austen Goslin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2=\"Linda Bean died at the age of ?\"\n",
        "result_simi2 = db.similarity_search(query2 , k = 5)\n",
        "source_knowledge2 = \"\\n\".join([x.page_content for x in result_simi2])\n",
        "augmented_prompt2 = \"\"\"Using the contexts below, answer the query.\n",
        "contexts:\n",
        "{source_knowledge2}\n",
        "\n",
        "query: {query2}\"\"\"\n",
        "\n",
        "prompt2 = PromptTemplate(template=augmented_prompt2, input_variables=[\"source_knowledge2\" ,\"query2\"])\n",
        "llm_chain2 = LLMChain(prompt=prompt2, llm=llm  , llm_kwargs = {\"temperature\":0.6, \"max_length\":1024})\n",
        "print(llm_chain2.run( {\"source_knowledge2\":source_knowledge2 ,\"query2\" : query2 }))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUP4oyATZ2o8",
        "outputId": "51e3016e-9059-49f7-e204-cb713205afe7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n"
          ]
        }
      ]
    }
  ]
}